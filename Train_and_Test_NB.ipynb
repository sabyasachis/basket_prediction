{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, log_loss\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_PATH  = \"/Users/saby/Projects/playground/so1/input\"\n",
    "OUTPUT_PATH = \"/Users/saby/Projects/playground/so1/output\"\n",
    "FEATURE_PATH = \"/Users/saby/Projects/playground/so1/features\"\n",
    "TRAIN_FILE_NAME  = \"train.csv\"\n",
    "OUTPUT_FILE_NAME = \"submit_1.csv\"\n",
    "FEATURE_FULL_FILE_NAME = \"df_full.csv\"\n",
    "\n",
    "\n",
    "FEATURE_USER_PREFIX = FEATURE_PATH + \"/\" + \"df_user_\"\n",
    "FEATURE_ITEM_PREFIX = FEATURE_PATH + \"/\" + \"df_item_\"\n",
    "FEATURE_USIT_PREFIX = FEATURE_PATH + \"/\" + \"df_user_item_\"\n",
    "\n",
    "TRAIN_FILE  =  INPUT_PATH + \"/\" +  TRAIN_FILE_NAME\n",
    "OUTPUT_FILE = OUTPUT_PATH + \"/\" + OUTPUT_FILE_NAME\n",
    "FEATURE_FULL_FILE = FEATURE_PATH + \"/\" + FEATURE_FULL_FILE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_USER = 2000\n",
    "N_ITEM = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALIDATION=True\n",
    "SPLIT_SIZE=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data frame handling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to read csv to dataframe\n",
    "def df_read(FILE):\n",
    "    df = pd.read_csv(FILE)\n",
    "    df.rename(columns={'i': 'user', 'j': 'item', 't': 'week'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Function to get a subset of original dataframe\n",
    "# based on some user or item ids or price thresholds\n",
    "def df_filter(df, user=None, item=None, week=None, price=None, advertised=None,\n",
    "                      price_up_thresh=None, price_low_thresh=None, week_up_thresh=None):\n",
    "    bool_arr = np.array([[True for i in range(df.shape[0])]])\n",
    "    if user is not None:\n",
    "        bool_arr = np.multiply(bool_arr, np.array([df['user'] == user]))\n",
    "    if item is not None:\n",
    "        bool_arr = np.multiply(bool_arr, np.array([df['item'] == item]))\n",
    "    if week is not None:\n",
    "        bool_arr = np.multiply(bool_arr, np.array([df['week'] == week]))\n",
    "    if price is not None:\n",
    "        bool_arr = np.multiply(bool_arr, np.array([df['price'] == price]))\n",
    "    if advertised is not None:\n",
    "        bool_arr = np.multiply(bool_arr, np.array([df['advertised'] == advertised]))\n",
    "        \n",
    "    if price_up_thresh is not None:\n",
    "        bool_arr = np.multiply(bool_arr, np.array([df['price'] <= price_up_thresh]))\n",
    "    if price_low_thresh is not None:\n",
    "        bool_arr = np.multiply(bool_arr, np.array([df['price'] >= price_low_thresh]))\n",
    "    if week_up_thresh is not None:\n",
    "        bool_arr = np.multiply(bool_arr, np.array([df['week'] <= week_up_thresh]))\n",
    "\n",
    "    return df[bool_arr.transpose()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to get true values for a given week\n",
    "# to be used in evaluation\n",
    "def get_y_true(df, week):\n",
    "    df_week = df_filter(df, week=week)\n",
    "    y_true = np.zeros((N_USER, N_ITEM), 'float')\n",
    "    for index, row in df_week.iterrows():\n",
    "        y_true[int(row['user']), int(row['item'])] = 1\n",
    "    return y_true\n",
    "\n",
    "# Function to evaluate the prediction for a given week against ground truth value for that week\n",
    "# You can also use mnetrics like auc, precision, recall, f-score\n",
    "def evaluation_score(df, week, y_predict, metric='auc'):\n",
    "    y_true = get_y_true(df, week)\n",
    "    y_true = y_true.flatten()\n",
    "    y_predict = y_predict.flatten()\n",
    "    if metric == 'auc':\n",
    "        score = roc_auc_score(y_true, y_predict)\n",
    "    elif metric == 'precision':\n",
    "        score = precision_score(y_true, y_predict)\n",
    "    elif metric == 'recall':\n",
    "        score = recall_score(y_true, y_predict)\n",
    "    elif metric == 'f1':\n",
    "        score = f1_score(y_true, y_predict)\n",
    "    elif metric == 'log loss':\n",
    "        score = log_loss(y_true, y_predict)\n",
    "    elif metric == 'accuracy':\n",
    "        score = accuracy_score(y_true, y_predict)\n",
    "    else:\n",
    "        assert False\n",
    "    return score\n",
    "\n",
    "# Function to get evaluation scores for a given week whne all predictions are set as ZERO\n",
    "def baseline_zeros(df, week, metric):\n",
    "    y_predict = np.zeros((N_USER, N_ITEM), 'float')\n",
    "    return evaluation_score(df, week=week, y_predict=y_predict, metric=metric)\n",
    "\n",
    "# Function to get evaluation scores for a given week whne all predictions are set as ONE\n",
    "def baseline_ones(df, week, metric):\n",
    "    y_predict = np.ones((N_USER, N_ITEM), 'float')\n",
    "    return evaluation_score(df, week=week, y_predict=y_predict, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baseline_ones(df, week=0, metric='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engg handling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to return an empty dataframe of length n\n",
    "def df_init(n):\n",
    "    return pd.DataFrame(index=range(n))\n",
    "\n",
    "# Function to add a new column array into dataframe for given label\n",
    "# If the column with label already exist, it simply overwrites on existing label\n",
    "def df_add_column(df, label, arr):\n",
    "    df[label] = pd.Series(np.array(arr), index=df.index)\n",
    "    return df\n",
    "\n",
    "# Function to del a new column array into dataframe for given label\n",
    "def df_del_column(df, label):\n",
    "    df = df.drop(columns=[label])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model training begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76502, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>week</th>\n",
       "      <th>price</th>\n",
       "      <th>advertised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.137451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3.023893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  week     price  advertised\n",
       "0     4     7     0  2.137451           0\n",
       "1     6     1     0  0.863341           0\n",
       "2     8     6     0  0.799155           0\n",
       "3     8    25     0  3.023893           0\n",
       "4     9     6     0  0.799155           0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_read(TRAIN_FILE)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lets read some saved features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that reads week-wise features from set path and returns a merged dataframe\n",
    "# No need to sort along user and item, the returned dataaframe will be sorted\n",
    "def get_feature_df(df, week):\n",
    "    USER_FILE = FEATURE_USER_PREFIX + str(week) + '.csv'\n",
    "    ITEM_FILE = FEATURE_ITEM_PREFIX + str(week) + '.csv'\n",
    "    USIT_FILE = FEATURE_USIT_PREFIX + str(week) + '.csv'\n",
    "\n",
    "    df_user = df_read(USER_FILE)\n",
    "    df_item = df_read(ITEM_FILE)\n",
    "    df_user_item = df_read(USIT_FILE)\n",
    "\n",
    "    df_user.rename(columns={'USR_ID_user': 'USR_ITM_CURR_user'}, inplace=True)\n",
    "    df_item.rename(columns={'ITM_ID_item': 'USR_ITM_CURR_item'}, inplace=True)\n",
    "\n",
    "    # df_merged = user_item_df((indexed on)) + item_df\n",
    "    df_merged = pd.merge(left=df_user_item, right=df_item, on='USR_ITM_CURR_item', how='inner')\n",
    "    # df_merged = df_merged((indexed on)) + user_df\n",
    "    df_merged = pd.merge(left=df_merged, right=df_user, on='USR_ITM_CURR_user', how='inner')\n",
    "    \n",
    "    del df_user, df_item, df_user_item\n",
    "    gc.collect()\n",
    "    \n",
    "    #if week == 48:\n",
    "    #    return df_merged\n",
    "    #adding final output class for next week\n",
    "    label = 'PREDICT'\n",
    "    arr = get_y_true(df, week=week+1).flatten()\n",
    "    df_merged = df_add_column(df_merged, label, arr)\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "# Function to read the full feature while which is a collection of features from all weeks\n",
    "# Basically reading a csv which is a concatenate of all dataframes generated using above function\n",
    "def get_full_feature_df():\n",
    "    df = df_read(FEATURE_FULL_FILE)\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USR_ITM_CURR_user</th>\n",
       "      <th>USR_ITM_CURR_item</th>\n",
       "      <th>USR_ITM_CURR_buy</th>\n",
       "      <th>USR_ITM_PAST_past_order_count</th>\n",
       "      <th>USR_ITM_PAST_last_reorder_length</th>\n",
       "      <th>USR_ITM_PAST_avg_reorder_length</th>\n",
       "      <th>NEXT_week_id</th>\n",
       "      <th>NEXT_advertised</th>\n",
       "      <th>ITM_ID_price</th>\n",
       "      <th>ITM_ID_disc_price</th>\n",
       "      <th>...</th>\n",
       "      <th>USR_PAST_n_time</th>\n",
       "      <th>USR_PAST_n_item_per_n_time</th>\n",
       "      <th>USR_PAST_old_purchase_ratio</th>\n",
       "      <th>USR_CURR_old_purchase_ratio</th>\n",
       "      <th>USR_PAST_ad_worked_ratio</th>\n",
       "      <th>USR_PAST_total_money_spent</th>\n",
       "      <th>USR_PAST_avg_money_per_item</th>\n",
       "      <th>USR_PAST_avg_money_per_n_time</th>\n",
       "      <th>USR_PAST_avg_money_per_week</th>\n",
       "      <th>PREDICT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.717944</td>\n",
       "      <td>1.717944</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863341</td>\n",
       "      <td>0.863341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.366060</td>\n",
       "      <td>3.366060</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.699985</td>\n",
       "      <td>0.699985</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.012190</td>\n",
       "      <td>2.012190</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   USR_ITM_CURR_user  USR_ITM_CURR_item  USR_ITM_CURR_buy  \\\n",
       "0                  0                  0                 0   \n",
       "1                  0                  1                 0   \n",
       "2                  0                  2                 0   \n",
       "3                  0                  3                 0   \n",
       "4                  0                  4                 0   \n",
       "\n",
       "   USR_ITM_PAST_past_order_count  USR_ITM_PAST_last_reorder_length  \\\n",
       "0                              0                                 0   \n",
       "1                              0                                 0   \n",
       "2                              0                                 0   \n",
       "3                              0                                 0   \n",
       "4                              0                                 0   \n",
       "\n",
       "   USR_ITM_PAST_avg_reorder_length  NEXT_week_id  NEXT_advertised  \\\n",
       "0                              0.0             2                0   \n",
       "1                              0.0             2                0   \n",
       "2                              0.0             2                0   \n",
       "3                              0.0             2                0   \n",
       "4                              0.0             2                1   \n",
       "\n",
       "   ITM_ID_price  ITM_ID_disc_price   ...     USR_PAST_n_time  \\\n",
       "0      1.717944           1.717944   ...                   0   \n",
       "1      0.863341           0.863341   ...                   0   \n",
       "2      3.366060           3.366060   ...                   0   \n",
       "3      0.699985           0.699985   ...                   0   \n",
       "4      2.012190           2.012190   ...                   0   \n",
       "\n",
       "   USR_PAST_n_item_per_n_time  USR_PAST_old_purchase_ratio  \\\n",
       "0                         0.0                          0.0   \n",
       "1                         0.0                          0.0   \n",
       "2                         0.0                          0.0   \n",
       "3                         0.0                          0.0   \n",
       "4                         0.0                          0.0   \n",
       "\n",
       "   USR_CURR_old_purchase_ratio  USR_PAST_ad_worked_ratio  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                       0.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "\n",
       "   USR_PAST_total_money_spent  USR_PAST_avg_money_per_item  \\\n",
       "0                         0.0                          0.0   \n",
       "1                         0.0                          0.0   \n",
       "2                         0.0                          0.0   \n",
       "3                         0.0                          0.0   \n",
       "4                         0.0                          0.0   \n",
       "\n",
       "   USR_PAST_avg_money_per_n_time  USR_PAST_avg_money_per_week  PREDICT  \n",
       "0                            0.0                          0.0      0.0  \n",
       "1                            0.0                          0.0      0.0  \n",
       "2                            0.0                          0.0      0.0  \n",
       "3                            0.0                          0.0      0.0  \n",
       "4                            0.0                          0.0      0.0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = get_full_feature_df()\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create train, test split and training and predicting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if VALIDATION:\n",
    "    df_train, df_valid = train_test_split(df_full, test_size=SPLIT_SIZE)\n",
    "else:\n",
    "    df_train = df_full\n",
    "\n",
    "X_train = df_train.drop(['PREDICT'], axis=1).values\n",
    "y_train = np.array(df_train[\"PREDICT\"])\n",
    "del df_full, df_train\n",
    "gc.collect()\n",
    "\n",
    "if VALIDATION:\n",
    "    X_valid = df_valid.drop(['PREDICT'], axis=1).values\n",
    "    y_valid = np.array(df_valid[\"PREDICT\"])\n",
    "    del df_valid\n",
    "    gc.collect()\n",
    "\n",
    "print('train valid set ready for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train: Using xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.812112\tvalid-auc:0.809993\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.815725\tvalid-auc:0.812342\n",
      "[2]\ttrain-auc:0.817268\tvalid-auc:0.813109\n",
      "[3]\ttrain-auc:0.819185\tvalid-auc:0.813053\n",
      "[4]\ttrain-auc:0.821136\tvalid-auc:0.81381\n",
      "[5]\ttrain-auc:0.823166\tvalid-auc:0.814045\n",
      "[6]\ttrain-auc:0.825136\tvalid-auc:0.814014\n",
      "[7]\ttrain-auc:0.827042\tvalid-auc:0.813911\n",
      "[8]\ttrain-auc:0.829303\tvalid-auc:0.813914\n",
      "[9]\ttrain-auc:0.831725\tvalid-auc:0.813717\n",
      "[10]\ttrain-auc:0.834142\tvalid-auc:0.813515\n",
      "[11]\ttrain-auc:0.83575\tvalid-auc:0.813264\n",
      "[12]\ttrain-auc:0.837439\tvalid-auc:0.813086\n",
      "[13]\ttrain-auc:0.839225\tvalid-auc:0.812901\n",
      "[14]\ttrain-auc:0.841015\tvalid-auc:0.812397\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'auc'\n",
    "params['eta'] = 0.4\n",
    "params['max_depth'] = 10     # set it as 3 or 4\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "if VALIDATION:\n",
    "    d_valid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "else:\n",
    "    watchlist = [(d_train, 'train')]\n",
    "\n",
    "gbm = xgb.train(params, d_train, 500, watchlist, early_stopping_rounds=10, verbose_eval=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[37]\ttrain-auc:0.820113\tvalid-auc:0.815991 for eta about 0.4 and depth at 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting testing predictions based on past training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_week=week+2\n",
    "# df_test = get_feature_df(df, week=test_week)\n",
    "# X_test = df_test.drop(['PREDICT'], axis=1).values\n",
    "# y_test = np.array(df_test[\"PREDICT\"])\n",
    "\n",
    "# pred = np.array(gbm.predict(xgb.DMatrix(X_test)))\n",
    "# roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gbm.save_model('simple_model-test-full.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting predictions on final week test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if VALIDATION:\n",
    "    print(\"ALERT!!!!!!!!!!!\")\n",
    "    print(\"YOU ARE TRYING TO GENERATE PREDICTIONS IN VALIDATION MODE\")\n",
    "    print(\"PLEASE SET VALIDATION=False AND TRY AGAIN\")\n",
    "    # don't go beyond here with Run All\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating submission output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = get_feature_df(df, week=48)\n",
    "X_test = df_test.values\n",
    "pred = np.array(gbm.predict(xgb.DMatrix(X_test)))\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['CLASS'] = p_test\n",
    "sub.to_csv('simple_model-test-single-all.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
